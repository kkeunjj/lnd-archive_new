# ğŸ“š L&D ì•„í‹°í´ ì•„ì¹´ì´ë¸Œ

L&D, HR, Leadership ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì•„í‹°í´ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  ì•„ì¹´ì´ë¹™í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥

- âœ… **ìë™ ìŠ¤í¬ë˜í•‘**: GitHub Actionsë¡œ ë§¤ì¼ ì˜¤ì „ 9ì‹œ ìë™ ì‹¤í–‰
- âœ… **7ê°œ ì‚¬ì´íŠ¸ ëª¨ë‹ˆí„°ë§**: Degreed, Josh Bersin, SHRM, Unleash, DDI, Wharton, Korn Ferry
- âœ… **ì‹¤ì‹œê°„ í•„í„°ë§**: ì‚¬ì´íŠ¸ë³„, ì¹´í…Œê³ ë¦¬ë³„, ë‚ ì§œë³„ í•„í„°
- âœ… **ê²€ìƒ‰ ê¸°ëŠ¥**: ì œëª©, ìš”ì•½, íƒœê·¸ ê²€ìƒ‰
- âœ… **ë°˜ì‘í˜• ë””ìì¸**: ëª¨ë°”ì¼, íƒœë¸”ë¦¿, ë°ìŠ¤í¬í†± ì§€ì›

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ld-article-archive/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ scrape.yml          # GitHub Actions ìë™í™” ì„¤ì •
â”œâ”€â”€ index.html                  # ë©”ì¸ ì›¹í˜ì´ì§€
â”œâ”€â”€ scraper.py                  # ì•„í‹°í´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ articles.json               # ìˆ˜ì§‘ëœ ì•„í‹°í´ ë°ì´í„°
â”œâ”€â”€ requirements.txt            # Python íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€â”€ README.md                   # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
```

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. ë¡œì»¬ì—ì„œ ì‹¤í–‰

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/yourusername/ld-article-archive.git
cd ld-article-archive

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# ìŠ¤í¬ë˜í¼ ì‹¤í–‰
python scraper.py

# ë¡œì»¬ ì„œë²„ ì‹¤í–‰
python -m http.server 8000

# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°
# http://localhost:8000
```

### 2. GitHub Pagesë¡œ ë°°í¬

1. GitHubì— ì €ì¥ì†Œ ì—…ë¡œë“œ
2. Settings > Pagesë¡œ ì´ë™
3. Source: Deploy from a branch
4. Branch: main, Folder: / (root)
5. Save í´ë¦­

ë°°í¬ í›„ ì ‘ì†: `https://yourusername.github.io/ld-article-archive/`

### 3. Netlifyë¡œ ë°°í¬

1. [Netlify](https://www.netlify.com/)ì— ë¡œê·¸ì¸
2. "New site from Git" í´ë¦­
3. GitHub ì €ì¥ì†Œ ì—°ê²°
4. Build settings:
   - Build command: (ë¹„ì›Œë‘ê¸°)
   - Publish directory: `/`
5. Deploy í´ë¦­

## âš™ï¸ GitHub Actions ìë™í™”

### ì„¤ì • ë°©ë²•

ì´ë¯¸ `.github/workflows/scrape.yml` íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆì–´ ìë™ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.

**ìë™ ì‹¤í–‰ ì‹œê°„**: ë§¤ì¼ ì˜¤ì „ 9ì‹œ (í•œêµ­ ì‹œê°„, UTC 0ì‹œ)

### ìˆ˜ë™ ì‹¤í–‰

1. GitHub ì €ì¥ì†Œ í˜ì´ì§€ ì´ë™
2. "Actions" íƒ­ í´ë¦­
3. "Daily Article Scraper" ì›Œí¬í”Œë¡œìš° ì„ íƒ
4. "Run workflow" ë²„íŠ¼ í´ë¦­

### ì‘ë™ ë°©ì‹

1. **ë§¤ì¼ ì˜¤ì „ 9ì‹œ**: GitHub Actionsê°€ ìë™ìœ¼ë¡œ ì‹¤í–‰
2. **ìŠ¤í¬ë˜í¼ ì‹¤í–‰**: `scraper.py`ê°€ ìµœì‹  ì•„í‹°í´ ìˆ˜ì§‘
3. **ë³€ê²½ì‚¬í•­ í™•ì¸**: `articles.json` íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
4. **ìë™ ì»¤ë°‹**: ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì»¤ë°‹ & í‘¸ì‹œ
5. **ì›¹ì‚¬ì´íŠ¸ ì—…ë°ì´íŠ¸**: GitHub Pages/Netlifyê°€ ìë™ìœ¼ë¡œ ì¬ë°°í¬

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸

| ì‚¬ì´íŠ¸ | URL | ì¹´í…Œê³ ë¦¬ |
|--------|-----|----------|
| Degreed | https://degreed.com/experience/blog/ | L&D ì „ëµ ë° LX |
| Josh Bersin | https://joshbersin.com/ | TD |
| SHRM | https://www.shrm.org/topics-tools/news | ê¸°íƒ€ |
| Unleash | https://www.unleash.ai/learning-and-development/ | L&D ì „ëµ ë° LX |
| DDI | https://www.ddi.com/blogs | ë¦¬ë”ì‹­ |
| Wharton Knowledge | https://knowledge.wharton.upenn.edu/category/leadership/ | OD |
| Korn Ferry | https://www.kornferry.com/insights | TD |

## ğŸ¨ ì¹´í…Œê³ ë¦¬

- **L&D ì „ëµ ë° LX**: í•™ìŠµ ì „ëµ, í•™ìŠµ ê²½í—˜ ë””ìì¸
- **OD**: ì¡°ì§ ê°œë°œ, ë³€í™” ê´€ë¦¬
- **TD**: ì¸ì¬ ê°œë°œ, ìŠ¤í‚¬ ê¸°ë°˜ ì ‘ê·¼
- **ë¦¬ë”ì‹­**: ë¦¬ë”ì‹­ ê°œë°œ, ì½”ì¹­
- **Tech**: LXP, AI, í•™ìŠµ ë¶„ì„
- **ê¸°íƒ€**: ê¸°íƒ€ HR ê´€ë ¨ ì½˜í…ì¸ 

## ğŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ ì¶”ê°€

`scraper.py` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
def scrape_new_site(self):
    """Scrape New Site"""
    try:
        url = "https://newsite.com/articles"
        response = requests.get(url, headers=self.headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ì•„í‹°í´ ìš”ì†Œ ì°¾ê¸°
        articles = soup.find_all('article', limit=10)
        
        for article in articles:
            # ì œëª©, ë§í¬, ë‚ ì§œ, ìš”ì•½ ì¶”ì¶œ
            # ...
            
            self.articles.append({
                'date': date,
                'site': 'New Site',
                'title': title,
                'url': link,
                'summary': summary,
                'category': 'Your Category',
                'tags': ['tag1', 'tag2']
            })
    except Exception as e:
        print(f"Error scraping New Site: {e}")
```

### ìŠ¤í¬ë˜í•‘ ì‹œê°„ ë³€ê²½

`.github/workflows/scrape.yml` íŒŒì¼ì—ì„œ cron í‘œí˜„ì‹ ìˆ˜ì •:

```yaml
schedule:
  # ë§¤ì¼ ì˜¤í›„ 2ì‹œ (UTC 5ì‹œ)
  - cron: '0 5 * * *'
```

[Cron í‘œí˜„ì‹ ìƒì„±ê¸°](https://crontab.guru/)

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ìŠ¤í¬ë˜í•‘ì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°

1. **ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ**: GitHub Actions ë¡œê·¸ í™•ì¸
2. **HTML êµ¬ì¡° ë³€ê²½**: ì›¹ì‚¬ì´íŠ¸ì˜ HTML ì„ íƒì ì—…ë°ì´íŠ¸ í•„ìš”
3. **ì ‘ê·¼ ì°¨ë‹¨**: User-Agent ë³€ê²½ ë˜ëŠ” ìš”ì²­ ê°„ê²© ì¡°ì •

### GitHub Actionsê°€ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš°

1. **ê¶Œí•œ í™•ì¸**: Settings > Actions > General
   - "Read and write permissions" ì„ íƒ
   - "Allow GitHub Actions to create and approve pull requests" ì²´í¬
2. **ì›Œí¬í”Œë¡œìš° í™œì„±í™”**: Actions íƒ­ì—ì„œ ì›Œí¬í”Œë¡œìš° Enable í™•ì¸

### ë¡œì»¬ì—ì„œ CORS ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°

íŒŒì¼ì„ ì§ì ‘ ì—´ì§€ ë§ê³  ë¡œì»¬ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
# Python 3
python -m http.server 8000

# Python 2
python -m SimpleHTTPServer 8000

# Node.js (npx ì‚¬ìš©)
npx http-server
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ê°œì¸ ë° ìƒì—…ì  ìš©ë„ë¡œ ììœ ë¡­ê²Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ¤ ê¸°ì—¬

ê°œì„  ì‚¬í•­ì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸ëŠ” ì–¸ì œë“  í™˜ì˜í•©ë‹ˆë‹¤!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ Issueë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

---

Made with â¤ï¸ for L&D Professionals
